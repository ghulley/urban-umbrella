{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpening ECOSTRESS LST using Harmonized Landsat Sentinel (HLS) VSWIR products (30m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook : Quentin Dehaene, mentored by Glynn Hulley    \n",
    "Original Python Implementation : [Radoslaw Guzinski](https://github.com/radosuav/pyDMS)  \n",
    "Original Implemenation : [Gao et al.](https://doi.org/10.3390/rs4113287) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions : quentin.dehaene@jpl.nasa.gov   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cell\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import rasterio.mask\n",
    "import rasterio.windows\n",
    "import random\n",
    "from pyDMS_master.pyDMS_master.run_pyDMS import *\n",
    "# you will also need ipykernel to run this a python notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, HR will refer to the high-resolution image used to train our regression algorithm. LR will refer to the coarse resolution image that we are trying to upsample, in our case the ECOSTRESS LST at 70m.\n",
    "\n",
    "The first step is to reproject and subset LR to HR Coordinates Reference System (CRS) and extent. This means that the result, and all images in the process will be in the HR CRS and will share its extent. Even if it implies padding a smaller LR with nodata values to match the extents. Reversely, all the images bigger than HR would be cut.\n",
    "\n",
    "The second step consists in resampling HR to the coarse resolution of LR (producing a temporary file). In the process, we compute the homogeneity inside each coarse resolution pixel. We are computing here how “pure” each coarse pixel is, i.e. how different are high resolution pixels that compose the coarse resolution pixel. For instance, if a coarse pixel is on a field, then it is very likely that all the high-resolution pixels composing that coarse pixel will be very similar because the material will be homogenous. However, in cities, larger pixels may actually be composed of several materials (asphalt roof, sidewalk, vegetation) and therefore be far less homogenous. We’ll use this homogeneity as a weight factor in our training.\n",
    "\n",
    "The default threshold is 80%, meaning that the 20% of pixels that are the least homogenous will be disregarded for the training.\n",
    "\n",
    "We can now start the training and fit the resampled HR to the LR.\n",
    "\n",
    "For those interested in how the tree is conceived:\n",
    "\n",
    "We are training a bagging of an ensemble of regression trees. Each of these trees is slightly more complicated than the usual regression tree. The principle of the tree is classic: each node is built to minimize the mean square error (MSE), hence each rule is made to split the data into different categories (the number of leaves being a parameter chosen here) and then we affect a value to each datum (each pixel in our case) falling into that category. The difference here lays in the way we determine the target value on each leaf: instead of giving the average of the y values (i.e. the LST) to all features in the leaf, we apply a Bayesian linear regression. We also have a limit as to how far from the training samples we can extrapolate when we predict with our regression tree.\n",
    "\n",
    "The tree is thus trained using the resampled HR as $X_{train}$ and the reprojected LR as $y_{train}$ (ground truth). Our tree is trained at low resolution, because it is at this resolution that we have what we know to be true and that we can actually establish a link between reflectance and LST.\n",
    "\n",
    "Now that the tree is trained, we can use it to make predictions. For that, we use the provided HR as X. We obtain a first prediction of the LST ($y_{pred}$) at the high resolution.\n",
    "\n",
    "Then, comes the residual analysis: We compute the residual (y-$y_{pred}$) at the coarse resolution. We compare our predicted LST, resampled at the coarse resolution, to the original LR. For that, we don’t actually compare the LST but the $LST^4$ which is proportional to the exitance. It makes more sense, since physically, temperature doesn’t have to be conserved in the sharpening, the energy does. And sensors don’t measure temperature but radiance.\n",
    "\n",
    "The final step is to smooth the residual, resample it to the high resolution, and sum it with the $y_{pred}$, our LST predicted. We now have a final LST prediction that verifies that the average radiance of all the high-resolution pixels composing a coarse pixel is equal to the radiance in the original LST.\n",
    "\n",
    "This is our downscaled image that we were looking for.\n",
    "\n",
    "I would like to note that there are two other sharpening techniques implemented in the pyDMS code, developed (and still being developed as of July 2024) by R. Guzinski. All the steps are the same, the only difference is the regression tree itself. There is on one hand, the Neural Network regressor i.e. instead of the tree presented here, we are using an MLP tree from [scikit-learn](https://github.com/aigamedev/scikit-neuralnetwork). On the other hand, is the one that’s actually closer to the original proposition of Gao, it is based on a [Cubist](https://www.rulequest.com/cubist-unix.html) regressor.\n",
    "\n",
    "The results don’t differ significantly from what I have tried, I went to the oldest/default (and hence more fool-proofed) but I welcome any feedback from your end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path defining cell. When you type a directory, it shouldn't include the final / or \\ (otherwise you will get a syntax error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where all the HLS bands are located.This can remain empty if you already have a multiband HLS.\n",
    "hr_img_dir = r'' \n",
    "# Future path (and name) of the multiband HLS image to be used for sharpening. Pay attention to potential overwriting of previous HLS image.\n",
    "hr_img_path = r'' \n",
    "# Folder where all the ECOSTRESS Quality Control files are located. This can remain empty if you don't have any QC file.\n",
    "QC_dir = r''\n",
    "# Folder where all the ECOSTRESS LST files are located for the scene of interest. This can remain empty if your ECOSTRESS data is already scaled.\n",
    "lr_dir = r''\n",
    "# Folder where all the scaled ECOSTRESS LST files will be written for the scene of interest\n",
    "lr_dir_sc = r''  \n",
    "# Folder where all the sharpened ECOSTRESS LST files will be written for the scene of interest\n",
    "dst_dir = r''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HLS preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part assumes that you already have on you computer/server the HLS data product for the region of interest.\n",
    "\n",
    "Skip this cell if you have a single HLS raster that is already scaled and with muliple bands (should be 10 if it's a Sentinel product, 8 if it is Landsat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the band per band reflectances already exist in EPSG:4326' \n",
    "\n",
    "r = []\n",
    "for root, dirs, files in os.walk(hr_img_dir):\n",
    "    for name in files:\n",
    "        if name.endswith('RP_cropped.tif') : # the naming convention might differ, you need this to read the mozaic HLS tile over the expected area\n",
    "            path =  os.path.join(root, name) \n",
    "            if path.__contains__('S30') and not  (path.__contains__('Band_01') or path.__contains__('Band_09') or path.__contains__('Band_10') or path.__contains__('Band_05') or path.__contains__('Band_06')  or path.__contains__('Band_07')  or path.__contains__('Band_8A')or path.__contains__('Band_11')or path.__contains__('Band_12')) :                        \n",
    "                r.append(path)\n",
    "            elif path.__contains__('L30') and not  (path.__contains__('Band_10') or path.__contains__('Band_11')):\n",
    "                r.append(path)\n",
    "            \n",
    "nb_bands = len(r)            \n",
    "print('Number of bands: ',nb_bands) # Check that it's what's expected \n",
    "         \n",
    "reproj_list = list()\n",
    "refl_hls = list() \n",
    "\n",
    "for filename in r : \n",
    "    with rasterio.open(filename,'r') as solo_band_rp :\n",
    "        refl_hls.append(solo_band_rp.read().astype('int16')[0])\n",
    "        kwargs = solo_band_rp.meta.copy()\n",
    "        kwargs.update({'count': nb_bands,'dtype' :'float32'})\n",
    "    # The scaling is different if the HLS comes from Sentinel or Landsat\n",
    "    if filename.__contains__('S30') : \n",
    "        scale_list = [0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001]\n",
    "    elif filename.__contains__('L30') : \n",
    "        scale_list = [0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001]\n",
    "    else :\n",
    "        print('Scaling was not correctly performed, check the names of the single bands mozaics' )\n",
    "\n",
    "        \n",
    "with rasterio.open(hr_img_path, 'w', **kwargs) as dst:\n",
    "    for i in range (nb_bands) :\n",
    "        dst.write(refl_hls[i]*scale_list[i], i+1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECOSTRESS preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here too we assume that you have the ECOSTRESS data dowloaded alongside the Quality Control files if available. In the folder there's a tutorial on how to use [AppEEARS](https://appeears.earthdatacloud.nasa.gov/) and obtain it.  \n",
    "Preprocessing the QC files to make it usable by pyDMS.  \n",
    "Skip this cell if you have no QC file or if they already been processed previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in os.listdir(QC_dir) :\n",
    "    if not file.endswith('QF.tif') and not file.endswith('.xml') : # avoid the auxiliary files created by QGIS and avoid creating QF files using already created QF files\n",
    "        file_qc = os.path.join(QC_dir,file)\n",
    "        with rasterio.open(file_qc,'r') as f_qc :\n",
    "            qc_img = f_qc.read((1)) # read the QC file they are coded in 16 bits\n",
    "            qc_img[qc_img==-99999] = -1  # Nodata values are read as -99999, we change it to -1 so that the last two bits appear as 11 (which means pixel not produced) and be masked out in the end\n",
    "            qc_img_2 = qc_img & 0b11 # select only the last two bits\n",
    "            out_meta = f_qc.meta.copy()\n",
    "        \n",
    "        file_qf = file_qc.replace('.tif','_QF.tif')\n",
    "        with rasterio.open(file_qf,'w',**out_meta) as dst : \n",
    "            dst.write(qc_img_2,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell simply preprocessed the QC files that you downloaded along with the LST. The QC files are coded in bits and not in integers that could be easily understood by pyDMS as a mask file. That cell transformed these QC files into a Quality Flag files of integer numbers. \n",
    "0 means that the pixel was perfect, 1 means nominal quality pixel 2 means cloud detected and 3 means pixel not produced, we'll reject these later.  \n",
    "For more information on the QC files : https://lpdaac.usgs.gov/documents/423/ECO2_User_Guide_V1.pdf (section 2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the ECOSTRESS LST to normal Kelvin scale.  \n",
    "The LST product is actually scaled at 0.02, the GIS takes that scale in account before display so you might not see it. However, Python doesn't so we need to scaled our LST to regular Kelvin.  \n",
    "Skip this cell if your ECOSTRESS LST data is already scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(lr_dir) :\n",
    "        if file.endswith('001.tif') : # avoid the auxiliary files created by QGIS \n",
    "                with rasterio.open(os.path.join(lr_dir,file),'r') as lr_img: \n",
    "                        out_image=lr_img.read()\n",
    "                        out_meta = lr_img.meta\n",
    "                \n",
    "                out_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": out_image.shape[1],\n",
    "                        \"width\": out_image.shape[2],\n",
    "                        'dtype' :'float32'})    \n",
    "\n",
    "                if not os.path.exists(lr_dir_sc) :\n",
    "                        os.mkdir(lr_dir_sc)\n",
    "                dst_path = os.path.join(lr_dir_sc,file)\n",
    "                with rasterio.open(dst_path,'w',**out_meta) as dst : \n",
    "                        dst.write(out_image*0.002 +0.49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling using pyDMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing is now over. Let's sharpen using pyDMS. Use one of the following cells depending on the presence of Quality Control files and the desired extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have QC files, process them into QF files and use one these two cells :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use this cell, then the output extent will be the extent of the HR image. Thus, if the HLS has a bigger extent, then the edges will be padded with NaNs. If it is smaller, then the sharpened image's extent will be the HLS extent (pyDMS is coded that way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useDecisionTree = True # Change this to False if you want to use the Neural Network intead of the Decision tree\n",
    "\n",
    "files_sharpened = [] #list of the files sharpened\n",
    "\n",
    "# Loop through the directory of LST images\n",
    "for file in os.listdir(lr_dir_sc) :\n",
    "    if file.endswith('sh.tif') :\n",
    "        if not os.path.exists(dst_dir) :\n",
    "                        os.mkdir(dst_dir)\n",
    "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_HLS.tif')) # destination path for the sharpened images\n",
    "        \n",
    "        highResFilename = hr_img_path \n",
    "        lowResFilename = os.path.join(lr_dir_sc,file) \n",
    "        \n",
    "        # Locate the corresponding mask file (our QF processed earlier)\n",
    "        file_qc = 'QC'.join(file.rsplit('LST', 1))\n",
    "        file_qf = file_qc.replace('.tif','_QF.tif')\n",
    "        lowResMaskFilename = os.path.join(QC_dir,file_qf)\n",
    "    \n",
    "    \n",
    "        # Only sharpen the files where the proportion of ideal pixels is greater than tresh, here 75%\n",
    "        with rasterio.open(lowResMaskFilename,'r') as mask : \n",
    "            mask_array = mask.read(1)\n",
    "            mask_sz = mask_array.size\n",
    "            tresh= 0.75 # adjustable\n",
    "            \n",
    "        if np.count_nonzero(mask_array==0) + np.count_nonzero(mask_array==1)>tresh*mask_sz :\n",
    "            \n",
    "            commonOpts = {\"highResFiles\":               [highResFilename],\n",
    "                            \"lowResFiles\":                [lowResFilename],\n",
    "                            \"lowResQualityFiles\":         [lowResMaskFilename],\n",
    "                            \"lowResGoodQualityFlags\":     [0,1],\n",
    "                            \"cvHomogeneityThreshold\":     0,\n",
    "                            \"movingWindowSize\":           0,\n",
    "                            \"disaggregatingTemperature\":  True}\n",
    "            dtOpts =     {\"perLeafLinearRegression\":    True,\n",
    "                            \"linearRegressionExtrapolationRatio\": 0.25}\n",
    "            sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
    "                            'activation':                 'tanh'}\n",
    "            nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
    "                            \"regressorOpt\":               sknnOpts}\n",
    "            \n",
    "            start_time = time.time()\n",
    "\n",
    "            if useDecisionTree:\n",
    "                opts = commonOpts.copy()\n",
    "                opts.update(dtOpts)\n",
    "                disaggregator = DecisionTreeSharpener(**opts)\n",
    "            else:\n",
    "                opts = commonOpts.copy()\n",
    "                opts.update(nnOpts)\n",
    "                disaggregator = NeuralNetworkSharpener(**opts)\n",
    "\n",
    "            print(\"Training regressor...\")\n",
    "            disaggregator.trainSharpener()\n",
    "            print(\"Sharpening...\")\n",
    "            downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
    "            print(\"Residual analysis...\")\n",
    "            residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
    "                                                                            lowResMaskFilename,\n",
    "                                                                            doCorrection=True)\n",
    "            print(\"Saving output...\")\n",
    "            highResFile = gdal.Open(highResFilename)\n",
    "            if correctedImage is not None:\n",
    "                outImage = correctedImage\n",
    "            else:\n",
    "                outImage = downscaledFile\n",
    "            outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                    outImage.GetGeoTransform(),\n",
    "                                    outImage.GetProjection(),\n",
    "                                    outputFilename)\n",
    "            residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                            residualImage.GetGeoTransform(),\n",
    "                                            residualImage.GetProjection(),\n",
    "                                            os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
    "                                            os.path.splitext(outputFilename)[1])\n",
    "            files_sharpened.append(file)\n",
    "            outFile = None\n",
    "            residualFile = None\n",
    "            downsaceldFile = None\n",
    "            highResFile = None\n",
    "\n",
    "            print(time.time() - start_time, \"seconds\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the ECOSTRESS image is completely included in the HLS image, then if desired, it is possible to cut the HLS image to the extent of the ECOSTRESS image, or to an extent of the user's choosing (which also has to be included). This might be useful for any mathematical postprocessing, such as computing RMSE or residual, because such an image would not contain any NaNs, and images would share same extents. To do so, use this cell :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useDecisionTree = True # Change this to False if you want to use the Neural Network intead of the Decision tree\n",
    "\n",
    "files_sharpened = [] #list of the files sharpened\n",
    "\n",
    "# Loop through the directory of LST images\n",
    "for file in os.listdir(lr_dir_sc) :\n",
    "    if file.endswith('.tif') :\n",
    "        if not os.path.exists(dst_dir) :\n",
    "                        os.mkdir(dst_dir)\n",
    "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_HLS.tif')) # destination path for the sharpened images\n",
    "        lowResFilename = os.path.join(lr_dir_sc,file) \n",
    "        lr_ds = rasterio.open(lowResFilename)\n",
    "        \n",
    "        projwin = [lr_ds.bounds.left,lr_ds.bounds.top,lr_ds.bounds.right,lr_ds.bounds.bottom] # cut to the extent of the LR image\n",
    "        # projwin = [-118.08175, 34.16189, -117.998676, 34.112327] # example of a custom cutout over LA \n",
    "        \n",
    "\n",
    "        hr_img_path_clipped = hr_img_path.replace('.tif',f'_clipped.tif') # also produces a clipped version of the HR image\n",
    "        ds = gdal.Open(hr_img_path)\n",
    "        ds = gdal.Translate(hr_img_path_clipped, ds, projWin = projwin)\n",
    "        ds = None\n",
    "        lr_ds = None\n",
    "        \n",
    "        highResFilename = hr_img_path_clipped \n",
    "        \n",
    "        \n",
    "        # Locate the corresponding mask file (our QF processed earlier)\n",
    "        file_qc = 'QC'.join(file.rsplit('LST', 1))\n",
    "        file_qf = file_qc.replace('.tif','_QF.tif')\n",
    "        lowResMaskFilename = os.path.join(QC_dir,file_qf)\n",
    "    \n",
    "    \n",
    "        # Only sharpen the files where the proportion of ideal pixels is greater than tresh, here 75%\n",
    "        with rasterio.open(lowResMaskFilename,'r') as mask : \n",
    "            mask_array = mask.read(1)\n",
    "            mask_sz = mask_array.size\n",
    "            tresh= 0.75 # adjustable\n",
    "            \n",
    "        if np.count_nonzero(mask_array==0) + np.count_nonzero(mask_array==1)>tresh*mask_sz :\n",
    "            \n",
    "            commonOpts = {\"highResFiles\":               [highResFilename],\n",
    "                            \"lowResFiles\":                [lowResFilename],\n",
    "                            \"lowResQualityFiles\":         [lowResMaskFilename],\n",
    "                            \"lowResGoodQualityFlags\":     [0,1],\n",
    "                            \"cvHomogeneityThreshold\":     0,\n",
    "                            \"movingWindowSize\":           0,\n",
    "                            \"disaggregatingTemperature\":  True}\n",
    "            dtOpts =     {\"perLeafLinearRegression\":    True,\n",
    "                            \"linearRegressionExtrapolationRatio\": 0.25}\n",
    "            sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
    "                            'activation':                 'tanh'}\n",
    "            nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
    "                            \"regressorOpt\":               sknnOpts}\n",
    "            \n",
    "            start_time = time.time()\n",
    "\n",
    "            if useDecisionTree:\n",
    "                opts = commonOpts.copy()\n",
    "                opts.update(dtOpts)\n",
    "                disaggregator = DecisionTreeSharpener(**opts)\n",
    "            else:\n",
    "                opts = commonOpts.copy()\n",
    "                opts.update(nnOpts)\n",
    "                disaggregator = NeuralNetworkSharpener(**opts)\n",
    "\n",
    "            print(\"Training regressor...\")\n",
    "            disaggregator.trainSharpener()\n",
    "            print(\"Sharpening...\")\n",
    "            downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
    "            print(\"Residual analysis...\")\n",
    "            residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
    "                                                                            lowResMaskFilename,\n",
    "                                                                            doCorrection=True)\n",
    "            print(\"Saving output...\")\n",
    "            highResFile = gdal.Open(highResFilename)\n",
    "            if correctedImage is not None:\n",
    "                outImage = correctedImage\n",
    "            else:\n",
    "                outImage = downscaledFile\n",
    "            outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                    outImage.GetGeoTransform(),\n",
    "                                    outImage.GetProjection(),\n",
    "                                    outputFilename)\n",
    "            residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                            residualImage.GetGeoTransform(),\n",
    "                                            residualImage.GetProjection(),\n",
    "                                            os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
    "                                            os.path.splitext(outputFilename)[1])\n",
    "            files_sharpened.append(file)\n",
    "            outFile = None\n",
    "            residualFile = None\n",
    "            downsaceldFile = None\n",
    "            highResFile = None\n",
    "\n",
    "            print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you sharpen an image with no QC file, which can happen for instance if this a multi day aggregate, then use of these cells : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final product to the HR extent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useDecisionTree = True # Change this to False if you want to use the Neural Network intead of the Decision tree\n",
    "\n",
    "files_sharpened = [] #list of the files sharpened\n",
    "\n",
    "# Loop through the directory of LST images\n",
    "for file in os.listdir(lr_dir_sc) :\n",
    "    if file.endswith('.tif') :\n",
    "        if not os.path.exists(dst_dir) :\n",
    "                        os.mkdir(dst_dir)\n",
    "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_HLS.tif')) # destination path for the sharpened images\n",
    "        lowResFilename = os.path.join(lr_dir_sc,file)      \n",
    "        highResFilename = hr_img_path\n",
    "        lowResMaskFilename = ''\n",
    "\n",
    "            \n",
    "        commonOpts = {\"highResFiles\":               [highResFilename],\n",
    "                        \"lowResFiles\":                [lowResFilename],\n",
    "                        \"lowResQualityFiles\":         [lowResMaskFilename],\n",
    "                        \"lowResGoodQualityFlags\":     [],\n",
    "                        \"cvHomogeneityThreshold\":     0,\n",
    "                        \"movingWindowSize\":           0,\n",
    "                        \"disaggregatingTemperature\":  False}\n",
    "        dtOpts =     {\"perLeafLinearRegression\":    True,\n",
    "                        \"linearRegressionExtrapolationRatio\": 0.25}\n",
    "        sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
    "                        'activation':                 'tanh'}\n",
    "        nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
    "                        \"regressorOpt\":               sknnOpts}\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        if useDecisionTree:\n",
    "            opts = commonOpts.copy()\n",
    "            opts.update(dtOpts)\n",
    "            disaggregator = DecisionTreeSharpener(**opts)\n",
    "        else:\n",
    "            opts = commonOpts.copy()\n",
    "            opts.update(nnOpts)\n",
    "            disaggregator = NeuralNetworkSharpener(**opts)\n",
    "\n",
    "        print(\"Training regressor...\")\n",
    "        disaggregator.trainSharpener()\n",
    "        print(\"Sharpening...\")\n",
    "        downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
    "        print(\"Residual analysis...\")\n",
    "        residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
    "                                                                        lowResMaskFilename,\n",
    "                                                                        doCorrection=True)\n",
    "        print(\"Saving output...\")\n",
    "        highResFile = gdal.Open(highResFilename)\n",
    "        if correctedImage is not None:\n",
    "            outImage = correctedImage\n",
    "        else:\n",
    "            outImage = downscaledFile\n",
    "        outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                outImage.GetGeoTransform(),\n",
    "                                outImage.GetProjection(),\n",
    "                                outputFilename)\n",
    "        residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                        residualImage.GetGeoTransform(),\n",
    "                                        residualImage.GetProjection(),\n",
    "                                        os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
    "                                        os.path.splitext(outputFilename)[1])\n",
    "        files_sharpened.append(file)\n",
    "        outFile = None\n",
    "        residualFile = None\n",
    "        downsaceldFile = None\n",
    "        highResFile = None\n",
    "\n",
    "        print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final product to a smaller extent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useDecisionTree = True # Change this to False if you want to use the Neural Network intead of the Decision tree\n",
    "\n",
    "files_sharpened = [] #list of the files sharpened\n",
    "\n",
    "# Loop through the directory of LST images\n",
    "for file in os.listdir(lr_dir_sc) :\n",
    "    if file.endswith('.tif') :\n",
    "        if not os.path.exists(dst_dir) :\n",
    "                        os.mkdir(dst_dir)\n",
    "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_HLS.tif')) # destination path for the sharpened images\n",
    "        lowResFilename = os.path.join(lr_dir_sc,file)         \n",
    "        lr_ds = rasterio.open(lowResFilename)\n",
    "        \n",
    "        projwin = [lr_ds.bounds.left,lr_ds.bounds.top,lr_ds.bounds.right,lr_ds.bounds.bottom] # cut to the extent of the LR image\n",
    "        # projwin = [-118.08175, 34.16189, -117.998676, 34.112327] # example of a custom cutout over LA \n",
    "        \n",
    "\n",
    "        hr_img_path_clipped = hr_img_path.replace('.tif',f'_clipped.tif') # also produces a clipped version of the HR image\n",
    "        ds = gdal.Open(hr_img_path)\n",
    "        ds = gdal.Translate(hr_img_path_clipped, ds, projWin = projwin)\n",
    "        ds = None\n",
    "        lr_ds = None\n",
    "        \n",
    "        highResFilename = hr_img_path_clipped\n",
    "        lowResMaskFilename = ''\n",
    "\n",
    "            \n",
    "        commonOpts = {\"highResFiles\":               [highResFilename],\n",
    "                        \"lowResFiles\":                [lowResFilename],\n",
    "                        \"lowResQualityFiles\":         [lowResMaskFilename],\n",
    "                        \"lowResGoodQualityFlags\":     [],\n",
    "                        \"cvHomogeneityThreshold\":     0,\n",
    "                        \"movingWindowSize\":           0,\n",
    "                        \"disaggregatingTemperature\":  False}\n",
    "        dtOpts =     {\"perLeafLinearRegression\":    True,\n",
    "                        \"linearRegressionExtrapolationRatio\": 0.25}\n",
    "        sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
    "                        'activation':                 'tanh'}\n",
    "        nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
    "                        \"regressorOpt\":               sknnOpts}\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        if useDecisionTree:\n",
    "            opts = commonOpts.copy()\n",
    "            opts.update(dtOpts)\n",
    "            disaggregator = DecisionTreeSharpener(**opts)\n",
    "        else:\n",
    "            opts = commonOpts.copy()\n",
    "            opts.update(nnOpts)\n",
    "            disaggregator = NeuralNetworkSharpener(**opts)\n",
    "\n",
    "        print(\"Training regressor...\")\n",
    "        disaggregator.trainSharpener()\n",
    "        print(\"Sharpening...\")\n",
    "        downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
    "        print(\"Residual analysis...\")\n",
    "        residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
    "                                                                        lowResMaskFilename,\n",
    "                                                                        doCorrection=True)\n",
    "        print(\"Saving output...\")\n",
    "        highResFile = gdal.Open(highResFilename)\n",
    "        if correctedImage is not None:\n",
    "            outImage = correctedImage\n",
    "        else:\n",
    "            outImage = downscaledFile\n",
    "        \n",
    "        outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                outImage.GetGeoTransform(),\n",
    "                                outImage.GetProjection(),\n",
    "                                outputFilename)\n",
    "        residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                        residualImage.GetGeoTransform(),\n",
    "                                        residualImage.GetProjection(),\n",
    "                                        os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
    "                                        os.path.splitext(outputFilename)[1])\n",
    "        files_sharpened.append(file)\n",
    "        outFile = None\n",
    "        residualFile = None\n",
    "        downsaceldFile = None\n",
    "        highResFile = None\n",
    "\n",
    "        print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot one random sharpened image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one random sharpened file\n",
    "file = random.choice(files_sharpened)\n",
    "sharpened_file = os.path.join(dst_dir,file.replace('.tif','_sharp_HLS.tif'))\n",
    "raw_file = os.path.join(lr_dir_sc,file)\n",
    "with rasterio.open(raw_file,'r') as lr_img : \n",
    "    raw_lst = lr_img.read(1)\n",
    "with rasterio.open(sharpened_file,'r') as shrp_img :\n",
    "    shrp_lst = shrp_img.read(1)\n",
    "    \n",
    "# Plot the ECOSTRESS original product\n",
    "plt.figure(1)\n",
    "plt.imshow(raw_lst,cmap='viridis')\n",
    "plt.axis('off')\n",
    "plt.colorbar(label ='LST(K)')\n",
    "vmin, vmax = plt.gci().get_clim() # save the limits to share them in the second figure\n",
    "plt.title(\"ECOSTRESS LST 70m\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the ECOSTRESS sharpened product\n",
    "plt.figure(2)\n",
    "plt.imshow(shrp_lst,cmap='viridis',clim =(vmin,vmax))\n",
    "plt.axis('off')\n",
    "plt.colorbar(label ='LST(K)')\n",
    "plt.title(\"ECOSTRESS LST sharpened to 30m\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jvsrp_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
