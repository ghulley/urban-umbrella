{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpening ECOSTRESS LST using Sentinel-2 VSWIR products at High Resolution (<20m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook : Quentin Dehaene, mentored by Glynn Hulley    \n",
    "Original Python Implementation : [Radoslaw Guzinski](https://github.com/radosuav/pyDMS)  \n",
    "Original Implemenation : [Gao et al.](https://doi.org/10.3390/rs4113287) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions : quentin.dehaene@jpl.nasa.gov   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cell\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import rasterio.mask\n",
    "import rasterio.windows\n",
    "import random\n",
    "import datetime\n",
    "from datetime import date \n",
    "from sentinelhub import (SHConfig, DataCollection, SentinelHubCatalog, SentinelHubRequest, BBox, bbox_to_dimensions, CRS, MimeType, Geometry,MosaickingOrder)\n",
    "from pyDMS_master.pyDMS_master.run_pyDMS import *\n",
    "#  make sure all of the packages are installed (especially sentinelhubsince it is unlkely you have it installed already)\n",
    "# you will also need ipykernel to run this a python notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, HR will refer to the high-resolution image used to train our regression algorithm. LR will refer to the coarse resolution image that we are trying to upsample, in our case the ECOSTRESS LST at 70m.\n",
    "\n",
    "The first step is to reproject and subset LR to HR Coordinates Reference System (CRS) and extent. This means that the result, and all images in the process will be in the HR CRS and will share its extent. Even if it implies padding a smaller LR with nodata values to match the extents. Reversely, all the images bigger than HR would be cut.\n",
    "\n",
    "The second step consists in resampling HR to the coarse resolution of LR (producing a temporary file). In the process, we compute the homogeneity inside each coarse resolution pixel. We are computing here how “pure” each coarse pixel is, i.e. how different are high resolution pixels that compose the coarse resolution pixel. For instance, if a coarse pixel is on a field, then it is very likely that all the high-resolution pixels composing that coarse pixel will be very similar because the material will be homogenous. However, in cities, larger pixels may actually be composed of several materials (asphalt roof, sidewalk, vegetation) and therefore be far less homogenous. We’ll use this homogeneity as a weight factor in our training.\n",
    "\n",
    "The default threshold is 80%, meaning that the 20% of pixels that are the least homogenous will be disregarded for the training.\n",
    "\n",
    "We can now start the training and fit the resampled HR to the LR.\n",
    "\n",
    "For those interested in how the tree is conceived:\n",
    "\n",
    "We are training a bagging of an ensemble of regression trees. Each of these trees is slightly more complicated than the usual regression tree. The principle of the tree is classic: each node is built to minimize the mean square error (MSE), hence each rule is made to split the data into different categories (the number of leaves being a parameter chosen here) and then we affect a value to each datum (each pixel in our case) falling into that category. The difference here lays in the way we determine the target value on each leaf: instead of giving the average of the y values (i.e. the LST) to all features in the leaf, we apply a Bayesian linear regression. We also have a limit as to how far from the training samples we can extrapolate when we predict with our regression tree.\n",
    "\n",
    "The tree is thus trained using the resampled HR as $X_{train}$ and the reprojected LR as $y_{train}$ (ground truth). Our tree is trained at low resolution, because it is at this resolution that we have what we know to be true and that we can actually establish a link between reflectance and LST.\n",
    "\n",
    "Now that the tree is trained, we can use it to make predictions. For that, we use the provided HR as X. We obtain a first prediction of the LST ($y_{pred}$) at the high resolution.\n",
    "\n",
    "Then, comes the residual analysis: We compute the residual (y-$y_{pred}$) at the coarse resolution. We compare our predicted LST, resampled at the coarse resolution, to the original LR. For that, we don’t actually compare the LST but the $LST^4$ which is proportional to the exitance. It makes more sense, since physically, temperature doesn’t have to be conserved in the sharpening, the energy does. And sensors don’t measure temperature but radiance.\n",
    "\n",
    "The final step is to smooth the residual, resample it to the high resolution, and sum it with the $y_{pred}$, our LST predicted. We now have a final LST prediction that verifies that the average radiance of all the high-resolution pixels composing a coarse pixel is equal to the radiance in the original LST.\n",
    "\n",
    "This is our downscaled image that we were looking for.\n",
    "\n",
    "I would like to note that there are two other sharpening techniques implemented in the pyDMS code, developed (and still being developed as of July 2024) by R. Guzinski. All the steps are the same, the only difference is the regression tree itself. There is on one hand, the Neural Network regressor i.e. instead of the tree presented here, we are using an MLP tree from [scikit-learn](https://github.com/aigamedev/scikit-neuralnetwork). On the other hand, is the one that’s actually closer to the original proposition of Gao, it is based on a [Cubist](https://www.rulequest.com/cubist-unix.html) regressor.\n",
    "\n",
    "The results don’t differ significantly from what I have tried, I went to the oldest/default (and hence more fool-proofed) but I welcome any feedback from your end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentinel 2 product download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Sentinel data is free to access, but it requires to create an account to download data.\n",
    "First, if you don't have an account on [Copernicus Data Space](https://dataspace.copernicus.eu/), create one and log in.  \n",
    "Now access your User Settings : My Account > DashBoard > User Settings (bottom left)  \n",
    "Create a new OAuth client. And save your newly given token ID and password.  \n",
    "\n",
    "If you encounter problem with the S2 download please refer to this [Documentation](https://sentinelhub-py.readthedocs.io/en/latest/index.html) or to this [Copernicus Web page](https://dataspace.copernicus.eu/news/2023-9-28-accessing-sentinel-mission-data-new-copernicus-data-space-ecosystem-apis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your bounding box and its resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape at 20 m resolution: (1115, 988) pixels\n"
     ]
    }
   ],
   "source": [
    "# The coordinates of the bounding box of your choosing, in lat lon : (xmin,ymin,xmax,ymax)\n",
    "# Use the http://bboxfinder.com to find your box easily (already in the right order)\n",
    "aoi_coords_wgs_84 = (23.600006,37.909123,23.860245,38.081098) \n",
    "resolution = 20 # the resolution of your data in m 10 or 20 ( we could do 60 but the sharpening would be quite ininteresting)\n",
    "aoi_bbox = BBox(bbox = aoi_coords_wgs_84,crs=CRS.WGS84)\n",
    "aoi_size = bbox_to_dimensions(aoi_bbox,resolution = resolution)\n",
    "print(f\"Image shape at {resolution} m resolution: {aoi_size} pixels\") # The size of the box is limited to 2500 pixels in each direction\n",
    "if (aoi_size[0]>2499 or aoi_size[1]>2499) : \n",
    "    raise(ValueError(\"The box is limited to 2500 pixels in each direction, try again with a smaller bounding box.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The download scripts for the two possible resolutions : 10 or 20m. Request of the data at the desired time. The final product will contain the least cloud covergage possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SHConfig()\n",
    "config.sh_base_url = 'https://sh.dataspace.copernicus.eu'\n",
    "config.sh_token_url = 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token'\n",
    "config.sh_client_id =''\n",
    "config.sh_client_secret =''\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your time interval (beginning, end) : \n",
    "interval = (\"2023-06-01\", \"2023-06-30\") \n",
    "# Choose your output folder for the downloaded Sentinel-2 products \n",
    "s2_output_folder = r''\n",
    "\n",
    "# Request scripts\n",
    "evalscript_all_bands_u20 = \"\"\"\n",
    "    //VERSION=3\n",
    "    function setup() {\n",
    "        return {\n",
    "            input: [{\n",
    "                bands: [\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B11\",\"B12\"],\n",
    "                units: \"REFLECTANCE\"\n",
    "                \n",
    "            }],\n",
    "            output: {\n",
    "                bands: 10,\n",
    "                sampleType: \"FLOAT32\"\n",
    "            }\n",
    "        };\n",
    "    }\n",
    "\n",
    "    function evaluatePixel(sample) {\n",
    "        return [sample.B02,\n",
    "                sample.B03,\n",
    "                sample.B04,\n",
    "                sample.B05,\n",
    "                sample.B06,\n",
    "                sample.B07,\n",
    "                sample.B08,\n",
    "                sample.B8A,\n",
    "                sample.B11,\n",
    "                sample.B12];\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "evalscript_all_bands_u10 = \"\"\"\n",
    "    //VERSION=3\n",
    "    function setup() {\n",
    "        return {\n",
    "            input: [{\n",
    "                bands: [\"B02\",\"B03\",\"B04\",\"B08\"],\n",
    "                units: 'REFLECTANCE'\n",
    "            }],\n",
    "            output: {\n",
    "                bands: 4,\n",
    "                sampleType: \"FLOAT32\"\n",
    "            }\n",
    "        };\n",
    "    }\n",
    "\n",
    "    function evaluatePixel(sample) {\n",
    "        return [sample.B02,\n",
    "                sample.B03,\n",
    "                sample.B04,\n",
    "                sample.B08,];\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "if resolution == 20 : \n",
    "    request_all_bands_u20 = SentinelHubRequest(\n",
    "        data_folder=s2_output_folder,\n",
    "        evalscript=evalscript_all_bands_u20,\n",
    "        input_data=[\n",
    "            SentinelHubRequest.input_data(\n",
    "                data_collection = DataCollection.SENTINEL2_L2A.define_from(\"s2l2a\", service_url=config.sh_base_url),\n",
    "                time_interval = interval,\n",
    "                mosaicking_order=MosaickingOrder.LEAST_CC, \n",
    "                # this parameter means that each pixel will be selected in the time interval\n",
    "                # to get an image with the mininal cloud coverage\n",
    "            )\n",
    "        ],\n",
    "        responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n",
    "        bbox=aoi_bbox,\n",
    "        size=aoi_size,\n",
    "        config=config,\n",
    "    )\n",
    "    resp = request_all_bands_u20.save_data(show_progress = True)\n",
    "elif resolution == 10 :\n",
    "    request_all_bands_u10 = SentinelHubRequest(\n",
    "        data_folder=s2_output_folder,\n",
    "        evalscript=evalscript_all_bands_u10,\n",
    "        input_data=[\n",
    "            SentinelHubRequest.input_data(\n",
    "                data_collection = DataCollection.SENTINEL2_L2A.define_from(\"s2l2a\", service_url=config.sh_base_url),\n",
    "            time_interval = interval,\n",
    "                mosaicking_order = MosaickingOrder.LEAST_CC\n",
    "            )\n",
    "        ],\n",
    "        responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n",
    "        bbox=aoi_bbox,\n",
    "        size=aoi_size,\n",
    "        config=config,\n",
    "    )\n",
    "    \n",
    "    resp = request_all_bands_u10.save_data(show_progress= True)\n",
    "else : \n",
    "    print('Unexpected resolution please change it to 10 or 20')\n",
    "\n",
    "# This part is used to rename the files\n",
    "dirs = [d for d in os.listdir(s2_output_folder)]\n",
    "\n",
    "most_recent_dir = max(dirs, key=lambda d: os.path.getmtime(os.path.join(s2_output_folder, d)))\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "new_name = f\"S2_request_{timestamp}\"\n",
    "old_path = os.path.join(s2_output_folder, most_recent_dir)\n",
    "new_path = os.path.join(s2_output_folder, new_name)\n",
    "os.rename(old_path, new_path)\n",
    "beg = interval[0]\n",
    "end = interval [1]\n",
    "for files in os.listdir(new_path):\n",
    "    if files.__contains__('response') :\n",
    "        os.rename(os.path.join(new_path,files),os.path.join(new_path,f\"S2_{resolution}m_{beg}_{end}.tif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path defining cell. When you type a directory, it shouldn't include the final / or \\ (otherwise you will get a syntax error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the multiband S2 image to be used for sharpening. \n",
    "hr_img_path = r'' \n",
    "# Folder where all the ECOSTRESS Quality Control files are located. This can remain empty if you don't have any QC file.\n",
    "QC_dir = r''\n",
    "# Folder where all the ECOSTRESS LST files are located for the scene of interest. This can remain empty if your ECOSTRESS data is already scaled.\n",
    "lr_dir = r''\n",
    "# Folder where all the scaled ECOSTRESS LST files will be written for the scene of interest\n",
    "lr_dir_sc = r''  \n",
    "# Folder where all the sharpened ECOSTRESS LST files will be written for the scene of interest\n",
    "dst_dir = r''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing ECOSTRESS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that you have the ECOSTRESS data dowloaded alongside the Quality Control files if available. In the folder there's a tutorial on how to use [AppEEARS](https://appeears.earthdatacloud.nasa.gov/) and obtain it.  \n",
    "Preprocessing the QC files to make it usable by pyDMS.  \n",
    "Skip this cell if you have no QC file or if they already been processed previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in os.listdir(QC_dir) :\n",
    "    if not file.endswith('QF.tif') and not file.endswith('.xml') : # avoid the auxiliary files created by QGIS and avoid creating QF files using already created QF files\n",
    "        file_qc = os.path.join(QC_dir,file)\n",
    "        with rasterio.open(file_qc,'r') as f_qc :\n",
    "            qc_img = f_qc.read((1)) # read the QC file they are coded in 16 bits\n",
    "            qc_img[qc_img==-99999] = -1  # Nodata values are read as -99999, we change it to -1 so that the last two bits appear as 11 (which means pixel not produced) and be masked out in the end\n",
    "            qc_img_2 = qc_img & 0b11 # select only the last two bits\n",
    "            out_meta = f_qc.meta.copy()\n",
    "        \n",
    "        file_qf = file_qc.replace('.tif','_QF.tif')\n",
    "        with rasterio.open(file_qf,'w',**out_meta) as dst : \n",
    "            dst.write(qc_img_2,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell simply preprocessed the QC files that you downloaded along with the LST. The QC files are coded in bits and not in integers that could be easily understood by pyDMS as a mask file. That cell transformed these QC files into a Quality Flag files of integer numbers. \n",
    "0 means that the pixel was perfect, 1 means nominal quality pixel 2 means cloud detected and 3 means pixel not produced, we'll reject these later.  \n",
    "For more information on the QC files : https://lpdaac.usgs.gov/documents/423/ECO2_User_Guide_V1.pdf (section 2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the ECOSTRESS LST to normal Kelvin scale.  \n",
    "The LST product is actually scaled at 0.02, the GIS takes that scale in account before display so you might not see it. However, Python doesn't so we need to scaled our LST to regular Kelvin.  \n",
    "Skip this cell if your ECOSTRESS LST data is already scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(lr_dir) :\n",
    "        if file.endswith('001.tif') : # avoid the auxiliary files created by QGIS \n",
    "                with rasterio.open(os.path.join(lr_dir,file),'r') as lr_img: \n",
    "                        out_image=lr_img.read()\n",
    "                        out_meta = lr_img.meta\n",
    "                \n",
    "                out_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": out_image.shape[1],\n",
    "                        \"width\": out_image.shape[2],\n",
    "                        'dtype' :'float32'})    \n",
    "\n",
    "                if not os.path.exists(lr_dir_sc) :\n",
    "                        os.mkdir(lr_dir_sc)\n",
    "                dst_path = os.path.join(lr_dir_sc,file)\n",
    "                with rasterio.open(dst_path,'w',**out_meta) as dst : \n",
    "                        dst.write(out_image*0.002 +0.49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling using pyDMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing is now over. Let's sharpen using pyDMS. Use one of the following cells depending on the presence of Quality Control files and the desired extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have QC files, process them into QF files and use one these two cells :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use this cell, then the output extent will be the extent of the HR image. Thus, if the S2 image has a bigger extent, then the edges will be padded with NaNs. If it is smaller then the sharpened image's extent will be the S2 image extent (pyDMS is coded that way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useDecisionTree = True # Change this to False if you want to use the Neural Network intead of the Decision tree\n",
    "\n",
    "files_sharpened = [] # list of the files sharpened\n",
    "\n",
    "# Loop through the directory of LST images\n",
    "for file in os.listdir(lr_dir_sc) :\n",
    "    if file.endswith('.tif') :\n",
    "        if not os.path.exists(dst_dir) :\n",
    "                        os.mkdir(dst_dir)\n",
    "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_S2.tif')) # destination path for the sharpened images\n",
    "        \n",
    "        highResFilename = hr_img_path \n",
    "        lowResFilename = os.path.join(lr_dir_sc,file) \n",
    "        \n",
    "        # Locate the corresponding mask file (our QF processed earlier)\n",
    "        file_qc = 'QC'.join(file.rsplit('LST', 1))\n",
    "        file_qf = file_qc.replace('.tif','_QF.tif')\n",
    "        lowResMaskFilename = os.path.join(QC_dir,file_qf)\n",
    "    \n",
    "    \n",
    "        # Only sharpen the files where the proportion of ideal pixels is greater than tresh, here 75%\n",
    "        with rasterio.open(lowResMaskFilename,'r') as mask : \n",
    "            mask_array = mask.read(1)\n",
    "            mask_sz = mask_array.size\n",
    "            tresh= 0.75 # adjustable\n",
    "            \n",
    "        if np.count_nonzero(mask_array==0) + np.count_nonzero(mask_array==1)>tresh*mask_sz :\n",
    "            \n",
    "            commonOpts = {\"highResFiles\":               [highResFilename],\n",
    "                            \"lowResFiles\":                [lowResFilename],\n",
    "                            \"lowResQualityFiles\":         [lowResMaskFilename],\n",
    "                            \"lowResGoodQualityFlags\":     [0,1],\n",
    "                            \"cvHomogeneityThreshold\":     0,\n",
    "                            \"movingWindowSize\":           0,\n",
    "                            \"disaggregatingTemperature\":  True}\n",
    "            dtOpts =     {\"perLeafLinearRegression\":    True,\n",
    "                            \"linearRegressionExtrapolationRatio\": 0.25}\n",
    "            sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
    "                            'activation':                 'tanh'}\n",
    "            nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
    "                            \"regressorOpt\":               sknnOpts}\n",
    "            \n",
    "            start_time = time.time()\n",
    "\n",
    "            if useDecisionTree:\n",
    "                opts = commonOpts.copy()\n",
    "                opts.update(dtOpts)\n",
    "                disaggregator = DecisionTreeSharpener(**opts)\n",
    "            else:\n",
    "                opts = commonOpts.copy()\n",
    "                opts.update(nnOpts)\n",
    "                disaggregator = NeuralNetworkSharpener(**opts)\n",
    "\n",
    "            print(\"Training regressor...\")\n",
    "            disaggregator.trainSharpener()\n",
    "            print(\"Sharpening...\")\n",
    "            downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
    "            print(\"Residual analysis...\")\n",
    "            residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
    "                                                                            lowResMaskFilename,\n",
    "                                                                            doCorrection=True)\n",
    "            print(\"Saving output...\")\n",
    "            highResFile = gdal.Open(highResFilename)\n",
    "            if correctedImage is not None:\n",
    "                outImage = correctedImage\n",
    "            else:\n",
    "                outImage = downscaledFile\n",
    "            \n",
    "            outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                    outImage.GetGeoTransform(),\n",
    "                                    outImage.GetProjection(),\n",
    "                                    outputFilename)\n",
    "            residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                            residualImage.GetGeoTransform(),\n",
    "                                            residualImage.GetProjection(),\n",
    "                                            os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
    "                                            os.path.splitext(outputFilename)[1])\n",
    "            files_sharpened.append(file)\n",
    "            outFile = None\n",
    "            residualFile = None\n",
    "            downsaceldFile = None\n",
    "            highResFile = None\n",
    "\n",
    "            print(time.time() - start_time, \"seconds\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the ECOSTRESS image is completely included in the S2 image, then if desired, it is possible to cut the S2 image to the extent of the ECOSTRESS image, or to an extent of the user's choosing (which also has to be included). This might be useful for any mathematical postprocessing, such as computing RMSE or residual, because such an image would not contain any NaNs, and images would share same extents. To do so, use this cell :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useDecisionTree = True # Change this to False if you want to use the Neural Network intead of the Decision tree\n",
    "\n",
    "files_sharpened = [] #list of the files sharpened\n",
    "\n",
    "# Loop through the directory of LST images\n",
    "for file in os.listdir(lr_dir_sc) :\n",
    "    if file.endswith('.tif') :\n",
    "        if not os.path.exists(dst_dir) :\n",
    "                        os.mkdir(dst_dir)\n",
    "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_S2.tif')) # destination path for the sharpened images\n",
    "        lowResFilename = os.path.join(lr_dir_sc,file) \n",
    "        lr_ds = rasterio.open(lowResFilename)\n",
    "        \n",
    "        projwin = [lr_ds.bounds.left,lr_ds.bounds.top,lr_ds.bounds.right,lr_ds.bounds.bottom] # cut to the extent of the LR image\n",
    "        # projwin = [-118.08175, 34.16189, -117.998676, 34.112327] # example of a custom cutout over LA \n",
    "        \n",
    "\n",
    "        hr_img_path_clipped = hr_img_path.replace('.tif',f'_clipped.tif') # also produces a clipped version of the HR image\n",
    "        ds = gdal.Open(hr_img_path)\n",
    "        ds = gdal.Translate(hr_img_path_clipped, ds, projWin = projwin)\n",
    "        ds = None\n",
    "        lr_ds = None\n",
    "        \n",
    "        highResFilename = hr_img_path_clipped \n",
    "        \n",
    "        \n",
    "        # Locate the corresponding mask file (our QF processed earlier)\n",
    "        file_qc = 'QC'.join(file.rsplit('LST', 1))\n",
    "        file_qf = file_qc.replace('.tif','_QF.tif')\n",
    "        lowResMaskFilename = os.path.join(QC_dir,file_qf)\n",
    "    \n",
    "    \n",
    "        # Only sharpen the files where the proportion of ideal pixels is greater than tresh, here 75%\n",
    "        with rasterio.open(lowResMaskFilename,'r') as mask : \n",
    "            mask_array = mask.read(1)\n",
    "            mask_sz = mask_array.size\n",
    "            tresh= 0.75 # adjustable\n",
    "            \n",
    "        if np.count_nonzero(mask_array==0) + np.count_nonzero(mask_array==1)>tresh*mask_sz :\n",
    "            \n",
    "            commonOpts = {\"highResFiles\":               [highResFilename],\n",
    "                            \"lowResFiles\":                [lowResFilename],\n",
    "                            \"lowResQualityFiles\":         [lowResMaskFilename],\n",
    "                            \"lowResGoodQualityFlags\":     [0,1],\n",
    "                            \"cvHomogeneityThreshold\":     0,\n",
    "                            \"movingWindowSize\":           0,\n",
    "                            \"disaggregatingTemperature\":  True}\n",
    "            dtOpts =     {\"perLeafLinearRegression\":    True,\n",
    "                            \"linearRegressionExtrapolationRatio\": 0.25}\n",
    "            sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
    "                            'activation':                 'tanh'}\n",
    "            nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
    "                            \"regressorOpt\":               sknnOpts}\n",
    "            \n",
    "            start_time = time.time()\n",
    "\n",
    "            if useDecisionTree:\n",
    "                opts = commonOpts.copy()\n",
    "                opts.update(dtOpts)\n",
    "                disaggregator = DecisionTreeSharpener(**opts)\n",
    "            else:\n",
    "                opts = commonOpts.copy()\n",
    "                opts.update(nnOpts)\n",
    "                disaggregator = NeuralNetworkSharpener(**opts)\n",
    "\n",
    "            print(\"Training regressor...\")\n",
    "            disaggregator.trainSharpener()\n",
    "            print(\"Sharpening...\")\n",
    "            downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
    "            print(\"Residual analysis...\")\n",
    "            residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
    "                                                                            lowResMaskFilename,\n",
    "                                                                            doCorrection=True)\n",
    "            print(\"Saving output...\")\n",
    "            highResFile = gdal.Open(highResFilename)\n",
    "            if correctedImage is not None:\n",
    "                outImage = correctedImage\n",
    "            else:\n",
    "                outImage = downscaledFile\n",
    "            \n",
    "            outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                    outImage.GetGeoTransform(),\n",
    "                                    outImage.GetProjection(),\n",
    "                                    outputFilename)\n",
    "            residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                            residualImage.GetGeoTransform(),\n",
    "                                            residualImage.GetProjection(),\n",
    "                                            os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
    "                                            os.path.splitext(outputFilename)[1])\n",
    "            files_sharpened.append(file)\n",
    "            outFile = None\n",
    "            residualFile = None\n",
    "            downsaceldFile = None\n",
    "            highResFile = None\n",
    "\n",
    "            print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final product to a smaller extent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useDecisionTree = True # Change this to False if you want to use the Neural Network intead of the Decision tree\n",
    "\n",
    "files_sharpened = [] #list of the files sharpened\n",
    "\n",
    "# Loop through the directory of LST images\n",
    "for file in os.listdir(lr_dir_sc) :\n",
    "    if file.endswith('.tif') :\n",
    "        if not os.path.exists(dst_dir) :\n",
    "                        os.mkdir(dst_dir)\n",
    "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_S2.tif')) # destination path for the sharpened images\n",
    "        lowResFilename = os.path.join(lr_dir_sc,file)         \n",
    "        lr_ds = rasterio.open(lowResFilename)\n",
    "        \n",
    "        projwin = [lr_ds.bounds.left,lr_ds.bounds.top,lr_ds.bounds.right,lr_ds.bounds.bottom] # cut to the extent of the LR image\n",
    "        # projwin = [-118.08175, 34.16189, -117.998676, 34.112327] # example of a custom cutout over LA \n",
    "        \n",
    "\n",
    "        hr_img_path_clipped = hr_img_path.replace('.tif',f'_clipped.tif') # also produces a clipped version of the HR image\n",
    "        ds = gdal.Open(hr_img_path)\n",
    "        ds = gdal.Translate(hr_img_path_clipped, ds, projWin = projwin)\n",
    "        ds = None\n",
    "        lr_ds = None\n",
    "        \n",
    "        highResFilename = hr_img_path_clipped\n",
    "        lowResMaskFilename = ''\n",
    "\n",
    "            \n",
    "        commonOpts = {\"highResFiles\":               [highResFilename],\n",
    "                        \"lowResFiles\":                [lowResFilename],\n",
    "                        \"lowResQualityFiles\":         [lowResMaskFilename],\n",
    "                        \"lowResGoodQualityFlags\":     [],\n",
    "                        \"cvHomogeneityThreshold\":     0,\n",
    "                        \"movingWindowSize\":           0,\n",
    "                        \"disaggregatingTemperature\":  False}\n",
    "        dtOpts =     {\"perLeafLinearRegression\":    True,\n",
    "                        \"linearRegressionExtrapolationRatio\": 0.25}\n",
    "        sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
    "                        'activation':                 'tanh'}\n",
    "        nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
    "                        \"regressorOpt\":               sknnOpts}\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        if useDecisionTree:\n",
    "            opts = commonOpts.copy()\n",
    "            opts.update(dtOpts)\n",
    "            disaggregator = DecisionTreeSharpener(**opts)\n",
    "        else:\n",
    "            opts = commonOpts.copy()\n",
    "            opts.update(nnOpts)\n",
    "            disaggregator = NeuralNetworkSharpener(**opts)\n",
    "\n",
    "        print(\"Training regressor...\")\n",
    "        disaggregator.trainSharpener()\n",
    "        print(\"Sharpening...\")\n",
    "        downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
    "        print(\"Residual analysis...\")\n",
    "        residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
    "                                                                        lowResMaskFilename,\n",
    "                                                                        doCorrection=True)\n",
    "        print(\"Saving output...\")\n",
    "        highResFile = gdal.Open(highResFilename)\n",
    "        if correctedImage is not None:\n",
    "            outImage = correctedImage\n",
    "        else:\n",
    "            outImage = downscaledFile\n",
    "        \n",
    "        outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                outImage.GetGeoTransform(),\n",
    "                                outImage.GetProjection(),\n",
    "                                outputFilename)\n",
    "        residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                        residualImage.GetGeoTransform(),\n",
    "                                        residualImage.GetProjection(),\n",
    "                                        os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
    "                                        os.path.splitext(outputFilename)[1])\n",
    "        files_sharpened.append(file)\n",
    "        outFile = None\n",
    "        residualFile = None\n",
    "        downsaceldFile = None\n",
    "        highResFile = None\n",
    "\n",
    "        print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you sharpen an image with no QC file, which can happen for instance if this a multi day aggregate, then use of these cells : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final product to the HR extent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useDecisionTree = True # Change this to False if you want to use the Neural Network intead of the Decision tree\n",
    "\n",
    "files_sharpened = [] #list of the files sharpened\n",
    "\n",
    "# Loop through the directory of LST images\n",
    "for file in os.listdir(lr_dir_sc) :\n",
    "    if file.endswith('.tif') :\n",
    "        if not os.path.exists(dst_dir) :\n",
    "                        os.mkdir(dst_dir)\n",
    "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_S2.tif')) # destination path for the sharpened images\n",
    "        lowResFilename = os.path.join(lr_dir_sc,file)         \n",
    "        highResFilename = hr_img_path\n",
    "        lowResMaskFilename = ''\n",
    "\n",
    "            \n",
    "        commonOpts = {\"highResFiles\":               [highResFilename],\n",
    "                        \"lowResFiles\":                [lowResFilename],\n",
    "                        \"lowResQualityFiles\":         [lowResMaskFilename],\n",
    "                        \"lowResGoodQualityFlags\":     [],\n",
    "                        \"cvHomogeneityThreshold\":     0,\n",
    "                        \"movingWindowSize\":           0,\n",
    "                        \"disaggregatingTemperature\":  False}\n",
    "        dtOpts =     {\"perLeafLinearRegression\":    True,\n",
    "                        \"linearRegressionExtrapolationRatio\": 0.25}\n",
    "        sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
    "                        'activation':                 'tanh'}\n",
    "        nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
    "                        \"regressorOpt\":               sknnOpts}\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        if useDecisionTree:\n",
    "            opts = commonOpts.copy()\n",
    "            opts.update(dtOpts)\n",
    "            disaggregator = DecisionTreeSharpener(**opts)\n",
    "        else:\n",
    "            opts = commonOpts.copy()\n",
    "            opts.update(nnOpts)\n",
    "            disaggregator = NeuralNetworkSharpener(**opts)\n",
    "\n",
    "        print(\"Training regressor...\")\n",
    "        disaggregator.trainSharpener()\n",
    "        print(\"Sharpening...\")\n",
    "        downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
    "        print(\"Residual analysis...\")\n",
    "        residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
    "                                                                        lowResMaskFilename,\n",
    "                                                                        doCorrection=True)\n",
    "        print(\"Saving output...\")\n",
    "        highResFile = gdal.Open(highResFilename)\n",
    "        if correctedImage is not None:\n",
    "            outImage = correctedImage\n",
    "        else:\n",
    "            outImage = downscaledFile\n",
    "        \n",
    "        outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                outImage.GetGeoTransform(),\n",
    "                                outImage.GetProjection(),\n",
    "                                outputFilename)\n",
    "        residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                        residualImage.GetGeoTransform(),\n",
    "                                        residualImage.GetProjection(),\n",
    "                                        os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
    "                                        os.path.splitext(outputFilename)[1])\n",
    "        files_sharpened.append(file)\n",
    "        outFile = None\n",
    "        residualFile = None\n",
    "        downsaceldFile = None\n",
    "        highResFile = None\n",
    "\n",
    "        print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot one random sharpened image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one random sharpened file\n",
    "file = random.choice(files_sharpened)\n",
    "sharpened_file = os.path.join(dst_dir,file.replace('.tif','_sharp_S2.tif'))\n",
    "raw_file = os.path.join(lr_dir_sc,file)\n",
    "with rasterio.open(raw_file,'r') as lr_img : \n",
    "    raw_lst = lr_img.read(1)\n",
    "with rasterio.open(sharpened_file,'r') as shrp_img :\n",
    "    shrp_lst = shrp_img.read(1)\n",
    "    \n",
    "# Plot the ECOSTRESS original product\n",
    "plt.figure(1)\n",
    "plt.imshow(raw_lst,cmap='viridis')\n",
    "plt.axis('off')\n",
    "plt.colorbar(label ='LST(K)')\n",
    "vmin, vmax = plt.gci().get_clim() # save the limits to share them in the second figure\n",
    "plt.title(\"ECOSTRESS LST 70m\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the ECOSTRESS sharpened product\n",
    "plt.figure(2)\n",
    "plt.imshow(shrp_lst,cmap='viridis',clim =(vmin,vmax))\n",
    "plt.axis('off')\n",
    "plt.colorbar(label ='LST(K)')\n",
    "plt.title(\"ECOSTRESS LST sharpened to 30m\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jvsrp_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
