{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpening ECOSTRESS LST using HLS VSWIR products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook : Quentin Dehaene, mentored by Glynn Hulley    \n",
    "Original Python Implementation : Radoslaw Guzinski  \n",
    "Original Implemenation : Gao et al. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions : quentin.dehaene@jpl.nasa.gov   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cell\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import rasterio.mask\n",
    "import rasterio.windows\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path defining cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where all the HLS bands are located\n",
    "hr_img_dir = r'' \n",
    "# Future path (and name) of the multiband HLS image to be used for sharpening. Pay attention to potential overwriting of previous HLS image.\n",
    "hr_img_path = r'' \n",
    "# Folder where all the ECOSTRESS Quality Control files are located\n",
    "QC_dir = r''\n",
    "# Folder where all the ECOSTRESS LST files are located for the scene of interest\n",
    "lr_dir = r''\n",
    "# Folder where all the scaled ECOSTRESS LST files will be written for the scene of interest\n",
    "lr_dir_sc = r''  \n",
    "# Folder where all the sharpened ECOSTRESS LST files will be written for the scene of interest\n",
    "dst_dir = r''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip this cell if you have a single HLS raster that is already scaled and with muliple bands (should be 10 if it's a Sentinel product, 8 if it is Landsat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bands:  10\n"
     ]
    }
   ],
   "source": [
    "# Make sure that the band per band reflectances already exist in EPSG:4326' \n",
    "\n",
    "r = []\n",
    "for root, dirs, files in os.walk(hr_img_dir):\n",
    "    for name in files:\n",
    "        if name.endswith('RP_cropped.tif') : # the naming convention might differ, you need this to read the mozaic HLS tile over the expected area\n",
    "            path =  os.path.join(root, name) \n",
    "            if path.__contains__('S30') and not  (path.__contains__('Band_01') or path.__contains__('Band_09') or path.__contains__('Band_10')) :                        \n",
    "                r.append(path)\n",
    "            elif path.__contains__('L30') and not  (path.__contains__('Band_10') or path.__contains__('Band_11')):\n",
    "                r.append(path)\n",
    "            \n",
    "nb_bands = len(r)            \n",
    "print('Number of bands: ',nb_bands) # Check that it's what's expected \n",
    "         \n",
    "reproj_list = list()\n",
    "refl_hls = list() \n",
    "\n",
    "for filename in r : \n",
    "    with rasterio.open(filename,'r') as solo_band_rp :\n",
    "        refl_hls.append(solo_band_rp.read().astype('int16')[0])\n",
    "        kwargs = solo_band_rp.meta.copy()\n",
    "        kwargs.update({'count': nb_bands,'dtype' :'float32'})\n",
    "    # The scaling is different if the HLS comes from Sentinel or Landsat\n",
    "    if filename.__contains__('S30') : \n",
    "        scale_list = [0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001]\n",
    "    elif filename.__contains__('L30') : \n",
    "        scale_list = [0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001]\n",
    "    else :\n",
    "        print('Scaling was not correctly performed, check the names of the single bands mozaics' )\n",
    "\n",
    "        \n",
    "with rasterio.open(hr_img_path, 'w', **kwargs) as dst:\n",
    "    for i in range (nb_bands) :\n",
    "        dst.write(refl_hls[i]*scale_list[i], i+1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the QC files to make it usable by pyDMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in os.listdir(QC_dir) :\n",
    "    if not file.endswith('QF.tif') and not file.endswith('.xml') : # avoid the auxiliary files created by QGIS and avoid creating QF files using already created QF files\n",
    "        file_qc = os.path.join(QC_dir,file)\n",
    "        with rasterio.open(file_qc,'r') as f_qc :\n",
    "            qc_img = f_qc.read((1)) # read the QC file they are coded in 16 bits\n",
    "            qc_img[qc_img==-99999] = -1  # Nodata values are read as -99999, we change it to -1 so that the last two bits appear as 11 (which means pixel not produced) and be masked out in the end\n",
    "            qc_img_2 = qc_img & 0b11 # select only the last two bits\n",
    "            out_meta = f_qc.meta.copy()\n",
    "        \n",
    "        file_qf = file_qc.replace('.tif','_QF.tif')\n",
    "        with rasterio.open(file_qf,'w',**out_meta) as dst : \n",
    "            dst.write(qc_img_2,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell simply preprocessed the QC files that you downloaded along with the LST. The QC files are coded in bits and not in integers that could be easily understood by pyDMS as a mask file. That cell transformed these QC files into a Quality Flag files of integer numbers. \n",
    "0 means that the pixel was perfect, 1 means nominal quality pixel 2 means cloud detected and 3 means pixel not produced, we'll reject these later.  \n",
    "For more information on the QC files : https://lpdaac.usgs.gov/documents/423/ECO2_User_Guide_V1.pdf (section 2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the ECOSTRESS LST to normal Kelvin scale  \n",
    "The LST product is actually scaled at 0.02, the GIS takes that scale in account before display so you might not see it. However, Python doesn't so we need to scaled our LST to regular Kelvin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(lr_dir) :\n",
    "        if file.endswith('.tif') : # avoid the auxiliary files created by QGIS \n",
    "                with rasterio.open(os.path.join(lr_dir,file),'r') as lr_img: \n",
    "                        out_image=lr_img.read()\n",
    "                        out_meta = lr_img.meta\n",
    "                \n",
    "                out_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": out_image.shape[1],\n",
    "                        \"width\": out_image.shape[2],\n",
    "                        'dtype' :'float32'})    \n",
    "\n",
    "                if not os.path.exists(lr_dir_sc) :\n",
    "                        os.mkdir(lr_dir_sc)\n",
    "                dst_path = os.path.join(lr_dir_sc,file)\n",
    "                with rasterio.open(dst_path,'w',**out_meta) as dst : \n",
    "                        dst.write(out_image*0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing is now over. Let's sharpen using pyDMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use this cell, then the output extent will be the extent of the HR image. Thus, if the HLS has a bigger extent, then the edges will be padded with NaNs. If it is smaller then the sharpened image's extent will be the HLS extent (pyDMS is coded that way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDMS_master.pyDMS_master.run_pyDMS import *\n",
    "\n",
    "useDecisionTree = True # Change this to False if you want to use the Neural Network intead of the Decision tree\n",
    "\n",
    "files_sharpened = [] #list of the files sharpened\n",
    "\n",
    "# Loop through the directory of LST images\n",
    "for file in os.listdir(lr_dir_sc) :\n",
    "    if file.endswith('.tif') :\n",
    "        if not os.path.exists(dst_dir) :\n",
    "                        os.mkdir(dst_dir)\n",
    "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_pyDMS.tif')) # destination path for the sharpened images\n",
    "        \n",
    "        highResFilename = hr_img_path \n",
    "        lowResFilename = os.path.join(lr_dir_sc,file) \n",
    "        \n",
    "        # Locate the corresponding mask file (our QF processed earlier)\n",
    "        file_qc = 'QC'.join(file.rsplit('LST', 1))\n",
    "        file_qf = file_qc.replace('.tif','_QF.tif')\n",
    "        lowResMaskFilename = os.path.join(QC_dir,file_qf)\n",
    "    \n",
    "    \n",
    "        # Only sharpen the files where the proportion of ideal pixels is greater than tresh, here 75%\n",
    "        with rasterio.open(lowResMaskFilename,'r') as mask : \n",
    "            mask_array = mask.read(1)\n",
    "            mask_sz = mask_array.size\n",
    "            tresh= 0.75 # adjustable\n",
    "            \n",
    "        if np.count_nonzero(mask_array==0) + np.count_nonzero(mask_array==1)>tresh*mask_sz :\n",
    "            \n",
    "            commonOpts = {\"highResFiles\":               [highResFilename],\n",
    "                            \"lowResFiles\":                [lowResFilename],\n",
    "                            \"lowResQualityFiles\":         [lowResMaskFilename],\n",
    "                            \"lowResGoodQualityFlags\":     [0,1],\n",
    "                            \"cvHomogeneityThreshold\":     0,\n",
    "                            \"movingWindowSize\":           0,\n",
    "                            \"disaggregatingTemperature\":  True}\n",
    "            dtOpts =     {\"perLeafLinearRegression\":    True,\n",
    "                            \"linearRegressionExtrapolationRatio\": 0.25}\n",
    "            sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
    "                            'activation':                 'tanh'}\n",
    "            nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
    "                            \"regressorOpt\":               sknnOpts}\n",
    "            \n",
    "            start_time = time.time()\n",
    "\n",
    "            if useDecisionTree:\n",
    "                opts = commonOpts.copy()\n",
    "                opts.update(dtOpts)\n",
    "                disaggregator = DecisionTreeSharpener(**opts)\n",
    "            else:\n",
    "                opts = commonOpts.copy()\n",
    "                opts.update(nnOpts)\n",
    "                disaggregator = NeuralNetworkSharpener(**opts)\n",
    "\n",
    "            print(\"Training regressor...\")\n",
    "            disaggregator.trainSharpener()\n",
    "            print(\"Sharpening...\")\n",
    "            downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
    "            print(\"Residual analysis...\")\n",
    "            residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
    "                                                                            lowResMaskFilename,\n",
    "                                                                            doCorrection=True)\n",
    "            print(\"Saving output...\")\n",
    "            highResFile = gdal.Open(highResFilename)\n",
    "            if correctedImage is not None:\n",
    "                outImage = correctedImage\n",
    "            else:\n",
    "                outImage = downscaledFile\n",
    "            # outData = utils.binomialSmoother(outData)\n",
    "            outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                    outImage.GetGeoTransform(),\n",
    "                                    outImage.GetProjection(),\n",
    "                                    outputFilename)\n",
    "            residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                            residualImage.GetGeoTransform(),\n",
    "                                            residualImage.GetProjection(),\n",
    "                                            os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
    "                                            os.path.splitext(outputFilename)[1])\n",
    "            files_sharpened.append(file)\n",
    "            outFile = None\n",
    "            residualFile = None\n",
    "            downsaceldFile = None\n",
    "            highResFile = None\n",
    "\n",
    "            print(time.time() - start_time, \"seconds\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the ECOSTRESS image is completely included in the HLS image, then if desired, it is possible to cut the HLS image to the extent of the ECOSTRESS image, or to an extent of the user's choosing (which also has to be included). This might be useful for any mathematical postprocessing, such as computing RMSE or residual, because such an image would not contain any NaNs, and images would share same extents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDMS_master.pyDMS_master.run_pyDMS import *\n",
    "\n",
    "useDecisionTree = True # Change this to False if you want to use the Neural Network intead of the Decision tree\n",
    "\n",
    "files_sharpened = [] #list of the files sharpened\n",
    "\n",
    "# Loop through the directory of LST images\n",
    "for file in os.listdir(lr_dir_sc) :\n",
    "    if file.endswith('.tif') :\n",
    "        if not os.path.exists(dst_dir) :\n",
    "                        os.mkdir(dst_dir)\n",
    "        outputFilename = os.path.join(dst_dir,file.replace('.tif','_sharp_pyDMS.tif')) # destination path for the sharpened images\n",
    "        lowResFilename = os.path.join(lr_dir_sc,file) \n",
    "        lr_ds = rasterio.open(lowResFilename)\n",
    "        \n",
    "        projwin = [lr_ds.bounds.left,lr_ds.bounds.top,lr_ds.bounds.right,lr_ds.bounds.bottom]\n",
    "        # projwin = [ -118.05943, 34.15509,-118.00927,34.11407 ] # example over LA of a custom cutout\n",
    "\n",
    "        hr_img_path_clipped = hr_img_path.replace('.tif',f'_clipped.tif') # also produces a clipped version of the HR image\n",
    "        ds = gdal.Open(hr_img_path)\n",
    "        ds = gdal.Translate(hr_img_path_clipped, ds, projWin = projwin)\n",
    "        ds = None\n",
    "        lr_ds = None\n",
    "        \n",
    "        highResFilename = hr_img_path_clipped \n",
    "        \n",
    "        \n",
    "        # Locate the corresponding mask file (our QF processed earlier)\n",
    "        file_qc = 'QC'.join(file.rsplit('LST', 1))\n",
    "        file_qf = file_qc.replace('.tif','_QF.tif')\n",
    "        lowResMaskFilename = os.path.join(QC_dir,file_qf)\n",
    "    \n",
    "    \n",
    "        # Only sharpen the files where the proportion of ideal pixels is greater than tresh, here 75%\n",
    "        with rasterio.open(lowResMaskFilename,'r') as mask : \n",
    "            mask_array = mask.read(1)\n",
    "            mask_sz = mask_array.size\n",
    "            tresh= 0.75 # adjustable\n",
    "            \n",
    "        if np.count_nonzero(mask_array==0) + np.count_nonzero(mask_array==1)>tresh*mask_sz :\n",
    "            \n",
    "            commonOpts = {\"highResFiles\":               [highResFilename],\n",
    "                            \"lowResFiles\":                [lowResFilename],\n",
    "                            \"lowResQualityFiles\":         [lowResMaskFilename],\n",
    "                            \"lowResGoodQualityFlags\":     [0,1],\n",
    "                            \"cvHomogeneityThreshold\":     0,\n",
    "                            \"movingWindowSize\":           0,\n",
    "                            \"disaggregatingTemperature\":  True}\n",
    "            dtOpts =     {\"perLeafLinearRegression\":    True,\n",
    "                            \"linearRegressionExtrapolationRatio\": 0.25}\n",
    "            sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
    "                            'activation':                 'tanh'}\n",
    "            nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
    "                            \"regressorOpt\":               sknnOpts}\n",
    "            \n",
    "            start_time = time.time()\n",
    "\n",
    "            if useDecisionTree:\n",
    "                opts = commonOpts.copy()\n",
    "                opts.update(dtOpts)\n",
    "                disaggregator = DecisionTreeSharpener(**opts)\n",
    "            else:\n",
    "                opts = commonOpts.copy()\n",
    "                opts.update(nnOpts)\n",
    "                disaggregator = NeuralNetworkSharpener(**opts)\n",
    "\n",
    "            print(\"Training regressor...\")\n",
    "            disaggregator.trainSharpener()\n",
    "            print(\"Sharpening...\")\n",
    "            downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
    "            print(\"Residual analysis...\")\n",
    "            residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
    "                                                                            lowResMaskFilename,\n",
    "                                                                            doCorrection=True)\n",
    "            print(\"Saving output...\")\n",
    "            highResFile = gdal.Open(highResFilename)\n",
    "            if correctedImage is not None:\n",
    "                outImage = correctedImage\n",
    "            else:\n",
    "                outImage = downscaledFile\n",
    "            # outData = utils.binomialSmoother(outData)\n",
    "            outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                    outImage.GetGeoTransform(),\n",
    "                                    outImage.GetProjection(),\n",
    "                                    outputFilename)\n",
    "            residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                            residualImage.GetGeoTransform(),\n",
    "                                            residualImage.GetProjection(),\n",
    "                                            os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
    "                                            os.path.splitext(outputFilename)[1])\n",
    "            files_sharpened.append(file)\n",
    "            outFile = None\n",
    "            residualFile = None\n",
    "            downsaceldFile = None\n",
    "            highResFile = None\n",
    "\n",
    "            print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot one random sharpened image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one random sharpened file\n",
    "file = random.choice(files_sharpened)\n",
    "sharpened_file = os.path.join(dst_dir,file.replace('.tif','_sharp_pyDMS.tif'))\n",
    "raw_file = os.path.join(lr_dir_sc,file)\n",
    "with rasterio.open(raw_file,'r') as lr_img : \n",
    "    raw_lst = lr_img.read(1)\n",
    "with rasterio.open(sharpened_file,'r') as shrp_img :\n",
    "    shrp_lst = shrp_img.read(1)\n",
    "    \n",
    "# Plot the ECOSTRESS original product\n",
    "plt.figure(1)\n",
    "plt.imshow(raw_lst,cmap='viridis')\n",
    "plt.axis('off')\n",
    "plt.colorbar(label ='LST(K)')\n",
    "vmin, vmax = plt.gci().get_clim() # save the limits to share them in the second figure\n",
    "plt.title(\"ECOSTRESS LST 70m\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the ECOSTRESS sharpened product\n",
    "plt.figure(2)\n",
    "plt.imshow(shrp_lst,cmap='viridis',clim =(vmin,vmax))\n",
    "plt.axis('off')\n",
    "plt.colorbar(label ='LST(K)')\n",
    "plt.title(\"ECOSTRESS LST sharpened to 30m\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jvsrp_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
